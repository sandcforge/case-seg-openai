#!/usr/bin/env python3
"""
Chunk processing module for customer support message segmentation.

This module contains:
- Pydantic models for LLM structured output
- Chunk class for processing message chunks and case segmentation
"""

import pandas as pd # type: ignore
from dataclasses import dataclass, field
from typing import List, Optional, Dict, Any, TYPE_CHECKING
from datetime import datetime
import copy
from collections import defaultdict

# Pydantic imports (only for LLM-compatible classes)
from typing import Literal
from pydantic import BaseModel, Field  # type: ignore

# Type checking imports to avoid circular dependencies
if TYPE_CHECKING:
    from llm_client import LLMClient


# ----------------------------
# Pydantic Models for Structured Output
# ----------------------------

@dataclass
class MetaInfo:
    """Meta information structure for each case"""
    tracking_numbers: List[str] = field(default_factory=list)
    order_numbers: List[str] = field(default_factory=list)
    user_names: List[str] = field(default_factory=list)

@dataclass
class CaseItem:
    """Individual case structure for case segmentation output"""
    case_id: Optional[int] = None  # Case ID (assigned during processing)
    msg_list: pd.DataFrame = field(default_factory=pd.DataFrame)
    summary: str = "N/A"
    status: str = "ongoing"  # open | ongoing | resolved | blocked
    pending_party: str = "N/A"  # seller|platform|N/A
    last_update: str = "N/A"  # ISO timestamp or N/A
    confidence: float = 0.0
    meta: Optional[MetaInfo] = None
    
    def __post_init__(self):
        """Initialize meta if not provided"""
        if self.meta is None:
            self.meta = MetaInfo()
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for JSON serialization"""
        return {
            'case_id': self.case_id,
            'msg_list': self.msg_list.to_dict('records') if not self.msg_list.empty else [],
            'summary': self.summary,
            'status': self.status,
            'pending_party': self.pending_party,
            'last_update': self.last_update,
            'confidence': self.confidence,
            'meta': {
                'tracking_numbers': self.meta.tracking_numbers,
                'order_numbers': self.meta.order_numbers,
                'user_names': self.meta.user_names
            } if self.meta else {}
        }

# LLM-Compatible Classes (for structured output generation)
class CaseItemForLLM(BaseModel):
    """LLM-compatible case structure using List[int] for msg_list"""
    model_config = {"extra": "forbid"}
    
    case_id: Optional[int] = None  # Case ID (assigned during processing)
    msg_list: List[int]  # List of message indices instead of DataFrame
    summary: str
    status: str  # open | ongoing | resolved | blocked
    pending_party: str  # seller|platform|N/A
    last_update: str  # ISO timestamp or N/A
    confidence: float
    meta: MetaInfo

class CasesSegmentationResponseForLLM(BaseModel):
    """LLM-compatible response structure for case segmentation"""
    model_config = {"extra": "forbid"}  # Ensures additionalProperties: false
    
    complete_cases: List[CaseItemForLLM]
    total_messages_analyzed: int
    llm_duration_seconds: Optional[float] = None


# Case Review Models (LLM-compatible)
class CaseReviewInput(BaseModel):
    """Input structure for case review"""
    model_config = {"extra": "forbid"}
    cases: List[CaseItemForLLM] = Field(..., description="ç›¸å…³çš„casesåˆ—è¡¨")
    overlap_msg_ids: List[int] = Field(..., description="é‡å åŒºåŸŸçš„æ¶ˆæ¯ID")
    all_messages: str = Field(..., description="æ‰€æœ‰ç›¸å…³æ¶ˆæ¯çš„æ–‡æœ¬")

class ReviewAction(BaseModel):
    """Single review action"""
    model_config = {"extra": "forbid"}
    action_type: Literal["merge", "split", "adjust_boundary", "no_change"] = Field(..., description="æ“ä½œç±»å‹")
    target_cases: List[int] = Field(..., description="ç›®æ ‡caseçš„ç´¢å¼•")
    new_msg_assignment: Dict[int, int] = Field(..., description="æ–°çš„æ¶ˆæ¯åˆ†é… {msg_id: case_index}")
    reason: str = Field(..., description="æ“ä½œåŸå› ")

class CaseReviewResponse(BaseModel):
    """Response structure for case review"""
    model_config = {"extra": "forbid"}
    review_actions: List[ReviewAction] = Field(..., description="reviewæ“ä½œåˆ—è¡¨")
    updated_cases: List[CaseItemForLLM] = Field(..., description="æ›´æ–°åçš„cases")
    confidence: float = Field(..., description="reviewç»“æœçš„ç½®ä¿¡åº¦", ge=0.0, le=1.0)


# ----------------------------
# Chunk Class
# ----------------------------

@dataclass
class Chunk:
    """Data structure for a single chunk of messages"""
    chunk_id: int                    # Sequential chunk ID (0, 1, 2, ...)
    channel_url: str                 # Channel this chunk belongs to
    messages: pd.DataFrame           # DataFrame slice with messages in this chunk
    has_segmentation_result: bool = False                    # Whether segmentation has been completed
    cases: List[CaseItem] = field(default_factory=list)  # Cached segmentation results
    
    @property
    def total_messages(self) -> int:
        """Number of messages in this chunk (calculated from DataFrame length)"""
        return len(self.messages)

    def get_message_indices(self) -> List[int]:
        """Get list of msg_ch_idx values for messages in this chunk"""
        return self.messages['msg_ch_idx'].tolist()
    
    def format_one_msg_for_prompt(self, row) -> str:
        """Format a single message row as: msg_ch_idx | sender_id | role | timestamp | text"""
        # Handle NaN messages and replace newlines with spaces to keep one line per message
        message_text = str(row['Message']).replace('\n', ' ').replace('\r', ' ')
        if message_text == 'nan':
            message_text = ''
        
        return f"{row['msg_ch_idx']} | {row['Sender ID']} | {row['role']} | {row['Created Time']} | {message_text}"
    
    def format_all_messages_for_prompt(self) -> str:
        """Format chunk messages as: message_index | sender id | role | timestamp | text"""
        formatted_lines = []
        for _, row in self.messages.iterrows():
            formatted_lines.append(self.format_one_msg_for_prompt(row))
        return '\n'.join(formatted_lines)
    

    def generate_case_segments(self, 
                             current_chunk_messages: str, 
                             llm_client: 'LLMClient') -> Dict[str, Any]:
        """Generate case segments using LLM for current chunk messages"""
        # Load the segmentation prompt template
        try:
            prompt_template = llm_client.load_prompt("segmentation_prompt.md")
        except FileNotFoundError as e:
            raise RuntimeError(f"Cannot load segmentation prompt: {e}")
        
        final_prompt = prompt_template.replace(
            "<<<INSERT_CHUNK_BLOCK_HERE>>>", 
            current_chunk_messages
        )
        
        # Generate case segments using LLM
        try:
            # Use structured output for OpenAI models, fallback to JSON parsing for Claude
            if llm_client.provider == "openai" and CasesSegmentationResponseForLLM:
                # Structured output with LLM-compatible schema (uses List[int] for msg_list)
                structured_response = llm_client.generate_structured(
                    final_prompt, 
                    CasesSegmentationResponseForLLM, 
                    call_label="case_segmentation"
                )
                
            # Convert LLM response to dict format that repair function expects
            raw_cases = []
            for case in structured_response.complete_cases:
                case_dict = {
                    'msg_list': case.msg_list,  # Keep as List[int] for repair function
                    'summary': case.summary,
                    'status': case.status,
                    'pending_party': case.pending_party,
                    'last_update': case.last_update,
                    'confidence': case.confidence,
                    'meta': {
                        'tracking_numbers': case.meta.tracking_numbers,
                        'order_numbers': case.meta.order_numbers,
                        'user_names': case.meta.user_names
                    }
                }
                raw_cases.append(case_dict)
                
            repair_result = self.repair_case_segment_output(
                cases=raw_cases,
                prev_context=None
            )
            
            # è½¬æ¢repairç»“æœä¸ºCaseItemå¯¹è±¡
            case_items = []
            for idx, case_dict in enumerate(repair_result['cases_out']):
                # ç¡®ä¿metaå­—æ®µæ ¼å¼æ­£ç¡®
                meta_dict = case_dict.get('meta', {})
                meta_info = MetaInfo(
                    tracking_numbers=meta_dict.get('tracking_numbers', []),
                    order_numbers=meta_dict.get('order_numbers', []),
                    user_names=meta_dict.get('user_names', [])
                )
                
                # å°†ç´¢å¼•åˆ—è¡¨è½¬æ¢ä¸ºDataFrame
                msg_indices = case_dict.get('msg_list', [])
                if msg_indices:
                    # ä»chunkçš„messages DataFrameä¸­æå–å¯¹åº”çš„è¡Œ
                    msg_dataframe = self.messages.iloc[msg_indices].copy().reset_index(drop=True)
                else:
                    # å¦‚æœæ²¡æœ‰æ¶ˆæ¯ï¼Œåˆ›å»ºç©ºçš„DataFrameï¼Œä¿æŒç›¸åŒçš„åˆ—ç»“æ„
                    msg_dataframe = self.messages.iloc[0:0].copy()
                
                case_item = CaseItem(
                    case_id=idx,  # Assign case_id based on index
                    msg_list=msg_dataframe,
                    summary=case_dict.get('summary', 'N/A'),
                    status=case_dict.get('status', 'ongoing'),
                    pending_party=case_dict.get('pending_party', 'N/A'),
                    last_update=case_dict.get('last_update', 'N/A'),
                    confidence=case_dict.get('confidence', 0.0),
                    meta=meta_info
                )
                case_items.append(case_item)
            
            # ç¼“å­˜ç»“æœ
            self.cases = case_items
            self.has_segmentation_result = True
            
            # æŠ¥å‘Šä¿®å¤æƒ…å†µ
            report = repair_result['report']
            provisionals = repair_result['provisionals']
            
            if provisionals:
                print(f"ğŸ”§ Applied {len(provisionals)} repair actions for chunk {self.chunk_id}:")
                for prov in provisionals:
                    if prov['type'] == 'duplicate_resolution':
                        print(f"  âœ Resolved duplicate msg {prov['msg_idx']}: kept in case {prov['chosen_case']}")
                    elif prov['type'] == 'auto_attach':
                        print(f"  â• Auto-attached msg {prov['msg_idx']} to case {prov['attached_to']}")
                    elif prov['type'] == 'misc_bucket':
                        print(f"  ğŸ“¦ Created misc case for {len(prov['msg_idxs'])} unassigned messages")
            
            # æœ€ç»ˆéªŒè¯
            if report['missing_msgs'] == 0 and report['duplicates_after'] == 0:
                print(f"âœ… Chunk {self.chunk_id} repair completed: 100% coverage achieved")
                print(f"   Final: {report['covered_msgs']}/{report['total_msgs']} messages in {report['total_cases_out']} cases")
            else:
                print(f"âš ï¸ Chunk {self.chunk_id} repair incomplete:")
                print(f"   Missing: {report['missing_msgs']}, Duplicates: {report['duplicates_after']}")
            
            # è¿”å›JSONæ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
            return repair_result['cases_out']
            
        except Exception as e:
            raise RuntimeError(f"Failed to generate case segments for chunk {self.chunk_id}: {e}")

    def repair_case_segment_output(self, 
                                 cases: List[Dict[str, Any]], 
                                 prev_context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        å¯¹å•ä¸ª chunk çš„ LLM åˆ†æ®µç»“æœè¿›è¡Œä¿®å¤ & æ ¡éªŒï¼ˆä¸ä¿®æ”¹å…¥å‚ï¼‰ã€‚
        - å»é‡ï¼šåŒä¸€ msg å‡ºç°åœ¨å¤šä¸ª caseï¼Œåªä¿ç•™ä¸€ä¸ªï¼ˆå¯è§£é‡Šçš„æ‹©ä¸€è§„åˆ™ï¼‰
        - æœªåˆ†é…ï¼šå¿…é¡»æŒ‚é åˆ°åˆç†çš„ caseï¼ˆç©ºæ¶ˆæ¯ä¼˜å…ˆæŒ‚é åˆ°ç›¸åŒsenderçš„æœ€è¿‘æ¶ˆæ¯ï¼‰
        - è¡¥é½å­—æ®µã€æ’åºç¨³å®šã€è‡ªæ£€æŠ¥å‘Š

        Args
        ----
        cases : List[Dict]      # LLM è¾“å‡ºçš„ cases
        prev_context : Optional[Dict]  # ä¸Šä¸€å—å°¾éƒ¨æ‘˜è¦ï¼Œç”¨äºæ‰¿æ¥åˆ¤æ–­

        Returns
        -------
        {
          "cases_out": List[Dict],
          "provisionals": List[Dict],   # å»é‡/è‡ªåŠ¨æŒ‚é çš„è®°å½•ï¼Œä¾¿äºåç»­å¤æ ¸
          "report": { ... }             # è‡ªæ£€ç»Ÿè®¡
        }
        """
        # å†…éƒ¨helperå‡½æ•°
        def _ensure_case_schema(c: Dict[str, Any]) -> Dict[str, Any]:
            """è¡¥é½å­—æ®µã€è§„èŒƒç±»å‹ï¼Œä¸æ”¹å…¥å‚ï¼ˆåœ¨å¤–å±‚ä¼š deepcopyï¼‰"""
            # Import from ChannelSegmenter constants
            REQUIRED_FIELDS_DEFAULTS = {
                "summary": "N/A",
                "status": "ongoing",
                "pending_party": "N/A",
                "last_update": "N/A",
                "confidence": 0.0,
                "meta": {
                    "tracking_numbers": [],
                    "order_numbers": [],
                    "user_names": []
                }
            }
            # Legacy anchor keys to meta field mapping
            ANCHOR_TO_META_MAPPING = {
                "tracking": "tracking_numbers",
                "order": "order_numbers", 
                "order_ids": "order_numbers",
                "buyer": "user_names",
                "buyers": "user_names"
            }
            
            if "msg_list" not in c or not isinstance(c["msg_list"], list):
                c["msg_list"] = []
            # ç»Ÿä¸€æ•´å‹ + å‡åºå»é‡
            c["msg_list"] = sorted({int(x) for x in c["msg_list"]})

            for k, v in REQUIRED_FIELDS_DEFAULTS.items():
                c.setdefault(k, copy.deepcopy(v))

            # å¤„ç†legacy anchorså­—æ®µï¼Œè½¬æ¢ä¸ºmetaç»“æ„
            if "anchors" in c and isinstance(c["anchors"], dict):
                # è¿ç§»anchorsåˆ°meta
                for anchor_key, meta_key in ANCHOR_TO_META_MAPPING.items():
                    anchor_value = c["anchors"].get(anchor_key)
                    if anchor_value is not None:
                        # ç»Ÿä¸€ä¸º list[str]
                        if isinstance(anchor_value, (str, int)):
                            meta_list = [str(anchor_value)]
                        elif isinstance(anchor_value, list):
                            meta_list = [str(x) for x in anchor_value if x is not None]
                        else:
                            meta_list = [str(anchor_value)]
                        
                        # åˆå¹¶åˆ°metaå­—æ®µï¼Œé¿å…é‡å¤
                        existing = set(c["meta"][meta_key])
                        c["meta"][meta_key] = list(existing.union(meta_list))
                
                # åˆ é™¤legacy anchorså­—æ®µ
                del c["anchors"]

            # ç¡®ä¿metaå­—æ®µç»“æ„æ­£ç¡®
            if not isinstance(c["meta"], dict):
                c["meta"] = copy.deepcopy(REQUIRED_FIELDS_DEFAULTS["meta"])
            
            # ç¡®ä¿metaä¸­çš„æ‰€æœ‰å¿…éœ€å­—æ®µå­˜åœ¨
            for field in ["tracking_numbers", "order_numbers", "user_names"]:
                if field not in c["meta"]:
                    c["meta"][field] = []
                elif not isinstance(c["meta"][field], list):
                    c["meta"][field] = []

            # è§„èŒƒ last_updateï¼ˆå®¹é”™ ISOï¼Œä¸å¯è§£æåˆ™ä¿ç•™åŸå€¼ï¼‰
            lu = c.get("last_update", "N/A")
            if isinstance(lu, str) and lu not in ("", "N/A"):
                try:
                    # å°è¯•è§£æï¼›å†ç»Ÿä¸€æˆ ISO æ ¼å¼
                    dt = datetime.fromisoformat(lu.replace("Z", "+00:00"))
                    c["last_update"] = dt.isoformat().replace("+00:00","Z")
                except Exception:
                    pass

            # ç½®ä¿¡åº¦è£å‰ª
            try:
                c["confidence"] = float(c.get("confidence", 0.0))
            except Exception:
                c["confidence"] = 0.0
            c["confidence"] = max(0.0, min(1.0, c["confidence"]))

            # çŠ¶æ€åˆæ³•æ€§
            if c.get("status") not in ("open", "ongoing", "resolved", "blocked"):
                c["status"] = "ongoing"

            return c
        
        def _anchor_strength(case: Dict[str, Any]) -> int:
            # tracking(4) > order(3) > buyer(2)
            meta = case.get("meta", {})
            if meta.get("tracking_numbers"): return 4
            if meta.get("order_numbers"): return 3
            if meta.get("user_names"): return 2
            return 0

        def _hits_active_hints(case: Dict[str, Any], prev_context: Optional[Dict[str, Any]]) -> bool:
            if not prev_context: return False
            hints = prev_context.get("ACTIVE_CASE_HINTS", [])
            if not hints: return False
            meta = case.get("meta", {})
            
            # Check meta fields against hints
            meta_fields = ["tracking_numbers", "order_numbers", "user_names"]
            for h in hints:
                h_meta = h.get("meta", {})
                for field in meta_fields:
                    case_values = set(meta.get(field, []))
                    hint_values = set(h_meta.get(field, []))
                    if case_values & hint_values:  # Intersection
                        return True
            return False

        def _proximity_score(i: int, case: Dict[str, Any]) -> float:
            ml = case.get("msg_list", [])
            if not ml: return 0.0
            # msg_list is still indices at repair stage
            dist = min(abs(i - m) for m in ml)
            return 1.0 / (1 + dist)  # 1, 0.5, 0.33, ...

        def _choose_one_for_duplicate(i: int, cases: List[Dict[str, Any]], cids: List[int], prev_context: Optional[Dict[str, Any]]) -> int:
            # è§„åˆ™ï¼šanchor_strength > æ‰¿æ¥(prev_context) > confidence > proximity > è¾ƒå° case_idï¼ˆç¨³å®šï¼‰
            scored = []
            for cid in cids:
                c = cases[cid]
                scored.append((
                    _anchor_strength(c),
                    1 if _hits_active_hints(c, prev_context) else 0,
                    float(c.get("confidence", 0.0)),
                    _proximity_score(i, c),
                    -cid,  # åå‘ç”¨äºæœ€åçš„ç¨³å®š tie-breakï¼ˆè¶Šå°ä¼˜å…ˆï¼‰
                    cid
                ))
            scored.sort(reverse=True)
            return scored[0][-1]

        def _is_empty_message(msg_idx: int) -> bool:
            """æ£€æŸ¥æ¶ˆæ¯å†…å®¹æ˜¯å¦ä¸ºç©ºæˆ–ç©ºç™½"""
            if msg_idx >= len(self.messages):
                return True
            message = self.messages.iloc[msg_idx]
            text = str(message.get('Text', '')).strip()
            return len(text) == 0
        
        def _find_nearest_same_sender_case(msg_idx: int, cases: List[Dict]) -> Optional[int]:
            """æŸ¥æ‰¾åŒ…å«æœ€è¿‘çš„ç›¸åŒsender_idæ¶ˆæ¯çš„case"""
            if msg_idx >= len(self.messages):
                return None
            
            target_sender = self.messages.iloc[msg_idx].get('Sender ID', '')
            if not target_sender:
                return None
            
            # æ„å»ºæ¶ˆæ¯åˆ°caseçš„æ˜ å°„
            msg_to_case = {}
            for case_idx, case in enumerate(cases):
                for msg_id in case.get('msg_list', []):
                    msg_to_case[msg_id] = case_idx
            
            # å¯»æ‰¾æœ€è¿‘çš„ç›¸åŒsenderæ¶ˆæ¯
            best_distance = float('inf')
            best_case_id = None
            
            for check_msg_idx, case_idx in msg_to_case.items():
                if check_msg_idx < len(self.messages):
                    check_sender = self.messages.iloc[check_msg_idx].get('Sender ID', '')
                    if check_sender == target_sender:
                        distance = abs(check_msg_idx - msg_idx)
                        if distance < best_distance:
                            best_distance = distance
                            best_case_id = case_idx
            
            return best_case_id
        
        def _attach_unassigned_smart(msg_idx: int, cases: List[Dict]) -> Optional[int]:
            """æ™ºèƒ½æŒ‚é é€»è¾‘ï¼ˆåŸºäºåŸ_attach_unassigned_simpleï¼‰"""
            scored = []
            for cid, c in enumerate(cases):
                # ä»…è€ƒè™‘ open/ongoing/blocked çš„ï¼Œè·³è¿‡ resolved
                if c.get("status") == "resolved":
                    continue
                scored.append((
                    1 if _hits_active_hints(c, prev_context) else 0,
                    _anchor_strength(c),
                    _proximity_score(msg_idx, c),
                    float(c.get("confidence", 0.0)),
                    -cid,
                    cid
                ))
            if not scored:
                return None
            scored.sort(reverse=True)
            # å¦‚æœå®Œå…¨æ²¡æœ‰ä¸Šä¸‹æ–‡å‘½ä¸­ä¸”é”šç‚¹/è´´è¿‘éƒ½å¾ˆå¼±ï¼Œå¯ä»¥é˜ˆå€¼ä¸¢å¼ƒï¼Œé¿å…è¯¯æŒ‚
            best = scored[0]
            cont, anc, prox, _, _, cid = best
            if (cont == 0 and anc == 0 and prox < 0.25):  # è´´è¿‘åº¦é˜ˆå€¼å¯è°ƒ
                return None
            return cid
        
        def _attach_to_any_nearest_case(msg_idx: int, cases: List[Dict]) -> int:
            """ç»ˆæå…œåº•ï¼šæŒ‚é åˆ°ä»»ä½•æœ€è¿‘çš„case"""
            if not cases:
                return 0  # å¦‚æœæ²¡æœ‰casesï¼Œè¿”å›ç¬¬ä¸€ä¸ªï¼ˆè¿™ç§æƒ…å†µç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼‰
            
            # æ‰¾åˆ°åŒ…å«æœ€è¿‘æ¶ˆæ¯çš„case
            best_distance = float('inf')
            best_case_id = 0
            
            for case_idx, case in enumerate(cases):
                for msg_id in case.get('msg_list', []):
                    distance = abs(msg_id - msg_idx)
                    if distance < best_distance:
                        best_distance = distance
                        best_case_id = case_idx
            
            return best_case_id
        
        def _attach_to_case(msg_idx: int, case_id: int, cases: List[Dict], provisionals: List[Dict], reason: str):
            """æ‰§è¡ŒæŒ‚é æ“ä½œ"""
            if case_id < len(cases):
                cases[case_id]["msg_list"].append(msg_idx)
                cases[case_id]["msg_list"] = sorted(set(cases[case_id]["msg_list"]))
                provisionals.append({
                    "type": "auto_attach",
                    "msg_idx": msg_idx,
                    "attached_to": case_id,
                    "reason": reason
                })
        
        # ä½¿ç”¨è‡ªå·±çš„æ¶ˆæ¯IDåˆ—è¡¨
        chunk_msg_ids = self.get_message_indices()
        
        out = copy.deepcopy(cases)

        # 1) è§„èŒƒåŒ– & è¡¥é½å­—æ®µ
        for idx in range(len(out)):
            out[idx] = _ensure_case_schema(out[idx])

        # 2) case å†…æ’åºç¨³å®š + å»ç©º case
        out = [c for c in out if c["msg_list"]]
        out.sort(key=lambda c: (c["msg_list"][0], c.get("confidence", 0.0) * -1))

        # 3) å»ºç«‹ msg -> cases åæŸ¥
        msg_to_cases = defaultdict(list)
        for cid, c in enumerate(out):
            for i in c["msg_list"]:
                msg_to_cases[i].append(cid)

        provisionals = []

        # 4) å»é‡ï¼šæ¯æ¡ msg åªä¿ç•™ä¸€ä¸ª case
        for i, cids in list(msg_to_cases.items()):
            if len(cids) <= 1:
                continue
            winner = _choose_one_for_duplicate(i, out, cids, prev_context)
            losers = [cid for cid in cids if cid != winner]
            # ä» loser ä¸­ç§»é™¤è¯¥ msg
            for cid in losers:
                ml = out[cid]["msg_list"]
                if i in ml:
                    out[cid]["msg_list"] = [x for x in ml if x != i]
            provisionals.append({
                "type": "duplicate_resolution",
                "msg_idx": i,
                "chosen_case": winner,
                "rejected_cases": losers,
                "reason": "anchor > continuation > confidence > proximity > case_id"
            })

        # 5) å†æ¬¡æ¸…ç†ç©º case
        out = [c for c in out if c["msg_list"]]
        # é‡æ–°æ„å»º msg ç´¢å¼•
        msg_to_cases.clear()
        for cid, c in enumerate(out):
            for i in c["msg_list"]:
                msg_to_cases[i].append(cid)

        # 6) è¯†åˆ«æœªåˆ†é…
        chunk_set = set(int(x) for x in chunk_msg_ids)
        assigned = set(msg_to_cases.keys())
        unassigned = sorted(list(chunk_set - assigned))

        # 7) æŒ‚é æœªåˆ†é…ï¼ˆå¿…é¡»å…¨éƒ¨æŒ‚é ï¼Œä¸‰å±‚ä¼˜å…ˆçº§ï¼‰
        for i in unassigned:
            cid = None
            reason = ""
            
            # ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šç©ºæ¶ˆæ¯æŒ‚é åˆ°ç›¸åŒsenderçš„æœ€è¿‘æ¶ˆæ¯
            if _is_empty_message(i):
                cid = _find_nearest_same_sender_case(i, out)
                if cid is not None:
                    reason = "empty_message_same_sender"
            
            # ç¬¬äºŒä¼˜å…ˆçº§ï¼šæ™ºèƒ½æŒ‚é é€»è¾‘
            if cid is None:
                cid = _attach_unassigned_smart(i, out)
                if cid is not None:
                    reason = "smart_attachment"
            
            # ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šç»ˆæå…œåº•æŒ‚é 
            if cid is None:
                cid = _attach_to_any_nearest_case(i, out)
                reason = "nearest_fallback"
            
            # æ‰§è¡ŒæŒ‚é ï¼ˆcidä¿è¯ä¸ä¸ºNoneï¼‰
            _attach_to_case(i, cid, out, provisionals, reason)

        # 8) æœ€ç»ˆæ’åºç¨³å®šï¼ˆæŒ‰æœ€å° msg å‡åºï¼‰
        out.sort(key=lambda c: c["msg_list"][0])

        # 9) è‡ªæ£€æŠ¥å‘Š
        # 9.1 ç»Ÿè®¡é‡å¤ä¸è¦†ç›–ç‡
        final_msg_to_cases = defaultdict(int)
        for c in out:
            for i in c["msg_list"]:
                final_msg_to_cases[i] += 1
        duplicates_after = [i for i, cnt in final_msg_to_cases.items() if cnt > 1]
        covered = set(final_msg_to_cases.keys())
        missing_after = sorted(list(chunk_set - covered))

        report = {
            "total_cases_in": len(cases),
            "total_cases_out": len(out),
            "total_msgs": len(chunk_set),
            "covered_msgs": len(covered),
            "missing_msgs": len(missing_after),
            "duplicates_after": len(duplicates_after),
            "duplicates_after_list": duplicates_after[:50],  # æˆªæ–­ï¼Œé¿å…è¿‡å¤§
        }

        return {
            "cases_out": out,
            "provisionals": provisionals,
            "report": report
        }
    
    def convert_llm_response_to_internal(self, llm_response: 'CasesSegmentationResponseForLLM') -> Dict[str, Any]:
        """Convert LLM-compatible response to internal format with DataFrames"""
        converted_cases = []
        
        for idx, case_llm in enumerate(llm_response.complete_cases):
            # Convert List[int] back to DataFrame
            msg_indices = case_llm.msg_list
            if msg_indices:
                # Extract corresponding rows from chunk's messages DataFrame
                msg_dataframe = self.messages.iloc[msg_indices].copy().reset_index(drop=True)
            else:
                # Empty DataFrame with same columns
                msg_dataframe = self.messages.iloc[0:0].copy()
            
            # Convert MetaInfo from Pydantic to dataclass
            meta_internal = MetaInfo(
                tracking_numbers=case_llm.meta.tracking_numbers,
                order_numbers=case_llm.meta.order_numbers,
                user_names=case_llm.meta.user_names
            )
            
            # Create internal CaseItem with DataFrame
            case_internal = CaseItem(
                case_id=case_llm.case_id if case_llm.case_id is not None else idx,
                msg_list=msg_dataframe,
                summary=case_llm.summary,
                status=case_llm.status,
                pending_party=case_llm.pending_party,
                last_update=case_llm.last_update,
                confidence=case_llm.confidence,
                meta=meta_internal
            )
            converted_cases.append(case_internal)
        
        return {
            'complete_cases': [case.to_dict() for case in converted_cases],
            'total_messages_analyzed': llm_response.total_messages_analyzed,
            'llm_duration_seconds': llm_response.llm_duration_seconds
        }